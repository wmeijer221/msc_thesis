{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script does all the logistic regression stuff using all of the data.\n",
    "It:\n",
    "- goes through all assumptions for logistic regression\n",
    "- alters the data wherever necessary to make things work\n",
    "- creates a classifier and evaluates its performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df)=182997\n",
      "17\n",
      "Index(['ControlIntegratedBySameUser', 'ControlPullRequestLifeTimeInMinutes',\n",
      "       'ControlPullRequestHasComments', 'ControlNumberOfCommitsInPullRequest',\n",
      "       'ControlPullRequestHasCommentByExternalUser',\n",
      "       'ControlHasHashTagInDescription',\n",
      "       'ControlIntraProjectPullRequestExperienceOfIntegrator',\n",
      "       'IntraProjectSubmitterPullRequestSubmissionCount',\n",
      "       'IntraProjectSubmitterPullRequestSuccessRate',\n",
      "       'IntraProjectSubmitterPullRequestCommentCount',\n",
      "       'EcosystemExperienceSubmitterPullRequestSuccessRate',\n",
      "       'EcosystemExperienceSubmitterPullRequestSubmissionCount',\n",
      "       'EcosystemExperienceSubmitterPullRequestCommentCount',\n",
      "       'SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator',\n",
      "       'SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter',\n",
      "       'EcosystemExperienceSubmitterIssueSubmissionCount',\n",
      "       'EcosystemExperienceSubmitterIssueCommentCount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import yeojohnson\n",
    "\n",
    "file_name = \"dataset_all_days_started_30_06_23\"\n",
    "data_path = f'/workspaces/msc_thesis/data/final_data/{file_name}.csv'\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(filepath_or_buffer=data_path, header=0)\n",
    "df = df.sample(math.floor(len(df) * 0.1))\n",
    "print(f'{len(df)=}')\n",
    "\n",
    "pr_merged_key = 'PullRequestIsMerged'\n",
    "\n",
    "dependent = df[pr_merged_key]\n",
    "dropped_fields = [\n",
    "        # Meta fields\n",
    "        'ID', 'Project Name', 'Submitter ID', 'PR Number', 'Closed At',\n",
    "\n",
    "        # dependent and control field\n",
    "        pr_merged_key, 'SubmitterIsFirstTimeContributor',\n",
    "\n",
    "        # Useless fields because they are (almost) all 0\n",
    "        \"DependencyEcosystemExperienceSubmitterIssueCommentCount\",\n",
    "        \"DependencyEcosystemExperienceSubmitterIssueSubmissionCount\",\n",
    "        'DependencyEcosystemExperienceSubmitterPullRequestSuccessRate',\n",
    "        \"DependencyEcosystemExperienceSubmitterPullRequestCommentCount\",\n",
    "        \"DependencyEcosystemExperienceSubmitterPullRequestSubmissionCount\",\n",
    "\n",
    "        \"IntraProjectSubmitterIssueCommentCount\",\n",
    "        \"IntraProjectSubmitterIssueSubmissionCount\",\n",
    "\n",
    "        \"InversedDependencyEcosystemExperienceSubmitterIssueCommentCount\",\n",
    "        \"InversedDependencyEcosystemExperienceSubmitterIssueSubmissionCount\",\n",
    "        'InversedDependencyEcosystemExperienceSubmitterPullRequestSuccessRate',\n",
    "        \"InversedDependencyEcosystemExperienceSubmitterPullRequestCommentCount\",\n",
    "        \"InversedDependencyEcosystemExperienceSubmitterPullRequestSubmissionCount\",\n",
    "\n",
    "        \"SharedExperienceIssueDiscussionParticipationByIntegratorAndSubmitter\",\n",
    "        'SharedExperienceIssueSubmittedByIntegratorCommentedOnBySubmitter',\n",
    "        \"SharedExperienceIssueSubmittedBySubmitterCommentedOnByIntegrator\",\n",
    "\n",
    "        \"SharedExperiencePullRequestDiscussionParticipationByIntegratorAndSubmitter\",\n",
    "        \"SharedExperiencePullRequestSubmittedByIntegratorCommentedOnBySubmitter\",\n",
    "        \"SharedExperiencePullRequestSubmittedBySubmitterCommentedOnByIntegrator\",\n",
    "    ]\n",
    "independent = df\n",
    "for field in dropped_fields:\n",
    "    independent = independent.drop(field, axis=1)\n",
    "\n",
    "print(len(independent.columns))\n",
    "print(independent.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-odds independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(continuous_vars.columns)=13\n",
      "(significant) ControlPullRequestLifeTimeInMinutes: p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ControlNumberOfCommitsInPullRequest: p=1.59579245644442e-45 (using 182677/182997 entries.)\n",
      "(significant) ControlIntraProjectPullRequestExperienceOfIntegrator: p=9.918950475822837e-199 (using 179287/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSubmissionCount: p=8.901734678532992e-133 (using 129195/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSuccessRate: p=2.5090634057971087e-33 (using 119303/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestCommentCount: p=1.0826221936684909e-52 (using 113692/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSuccessRate: p=8.656314461901004e-16 (using 117490/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSubmissionCount: p=4.2914653273240013e-206 (using 126559/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestCommentCount: p=2.8889823566087328e-70 (using 118986/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator: p=1.1257083511552487e-52 (using 53008/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter: p=4.987380113525745e-11 (using 14035/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueSubmissionCount: p=2.587195754971355e-218 (using 141101/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueCommentCount: p=1.9986965455267647e-192 (using 150656/182997 entries.)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "def show_log_odds_independence(__independent: pd.DataFrame, tested_field: str):\n",
    "    # Re-running logistic regression on the original set of X and y variables\n",
    "    logit_results = sm.GLM(dependent, __independent,\n",
    "                           family=sm.families.Binomial()).fit()\n",
    "    predicted = logit_results.predict(dependent)\n",
    "\n",
    "    # Getting log odds values\n",
    "    log_odds = np.log(predicted / (1 - predicted))\n",
    "\n",
    "    # Visualize predictor variable vs logit values for Age\n",
    "    plt.scatter(x=__independent[tested_field].values, y=log_odds)\n",
    "    plt.xlabel(tested_field)\n",
    "    plt.ylabel(\"Log-odds\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_log_odds_independence(__independents: pd.DataFrame):\n",
    "    continuous_vars = __independents.select_dtypes(include='number')\n",
    "    print(f'{len(continuous_vars.columns)=}')\n",
    "\n",
    "    # Define continuous variables\n",
    "    X_lt = continuous_vars.copy()\n",
    "\n",
    "    def x_ln_x(x):\n",
    "        # 1 is added to deal with zeroes.\n",
    "        return x * np.log(1 + x)\n",
    "\n",
    "    # Add logit transform interaction terms (natural log) for continuous variables.\n",
    "    ln_var_name_format = 'ln(.) x {var}'\n",
    "    for var in continuous_vars:\n",
    "        ln_var_name = ln_var_name_format.format(var=var)\n",
    "        X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
    "\n",
    "    working_transformations = []\n",
    "\n",
    "    for field in continuous_vars.columns:\n",
    "        ln_column = ln_var_name_format.format(var=field)\n",
    "\n",
    "        test_df = pd.DataFrame()\n",
    "        test_df[field] = X_lt[field]\n",
    "        test_df[ln_column] = X_lt[ln_column]\n",
    "\n",
    "\n",
    "        # Removes rows with zeroes\n",
    "        rows_that_are_zero = test_df.loc[test_df[field] == 0].index\n",
    "        test_df = test_df.drop(rows_that_are_zero)\n",
    "        test_dependent = dependent.drop(rows_that_are_zero)\n",
    "\n",
    "        # Add constant term\n",
    "        test_df = sm.add_constant(test_df, prepend=False)\n",
    "        \n",
    "        # Building model and fit the data.\n",
    "        logit_results = sm.GLM(test_dependent,\n",
    "                               test_df,\n",
    "                               family=sm.families.Binomial()\n",
    "                               ).fit()\n",
    "\n",
    "        p_value = logit_results.pvalues[1]\n",
    "        is_insignificant = p_value > 0.05\n",
    "        significance = \"insignificant\" if is_insignificant else \"significant\"\n",
    "\n",
    "        if is_insignificant:\n",
    "            working_transformations.append(field)\n",
    "\n",
    "        print(f'({significance}) {field}: p={p_value} (using {len(test_df)}/{len(X_lt)} entries.)')\n",
    "\n",
    "        # Display summary results\n",
    "        # print(logit_results.summary())\n",
    "\n",
    "    print(json.dumps(working_transformations, indent=4))\n",
    "\n",
    "# NOTE: Works for two:\n",
    "# - SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator\n",
    "# - EcosystemExperienceSubmitterIssueCommentCount\n",
    "test_log_odds_independence(independent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2014/3450970340.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'cbrt(1 + {field})'] =  independent[field].apply(lambda x: math.cbrt(1 + x))\n",
      "/tmp/ipykernel_2014/3450970340.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'ln(1 + {field})'] =  independent[field].apply(lambda x: math.log(1 + x))\n",
      "/tmp/ipykernel_2014/3450970340.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'log10(1 + {field})'] =  independent[field].apply(lambda x: math.log10(1 + x))\n",
      "/tmp/ipykernel_2014/3450970340.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'1 / (1 + {field})'] =  independent[field].apply(lambda x: 1 / (1 + x))\n",
      "/tmp/ipykernel_2014/3450970340.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'{field}^2'] =  independent[field].apply(lambda x: x ** 2)\n",
      "/tmp/ipykernel_2014/3450970340.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'{field}^3'] =  independent[field].apply(lambda x: x ** 3)\n",
      "/tmp/ipykernel_2014/3450970340.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  tr_independent[f'yj({field})'], _lambda = yeojohnson(independent[field])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(continuous_vars.columns)=117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n",
      "/tmp/ipykernel_2014/3912578958.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_lt[ln_var_name] = X_lt[var].apply(x_ln_x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(significant) ControlPullRequestLifeTimeInMinutes: p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ControlNumberOfCommitsInPullRequest: p=1.59579245644442e-45 (using 182677/182997 entries.)\n",
      "(significant) ControlIntraProjectPullRequestExperienceOfIntegrator: p=9.918950475822837e-199 (using 179287/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSubmissionCount: p=8.901734678532992e-133 (using 129195/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSuccessRate: p=2.5090634057971087e-33 (using 119303/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestCommentCount: p=1.0826221936684909e-52 (using 113692/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSuccessRate: p=8.656314461901004e-16 (using 117490/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSubmissionCount: p=4.2914653273240013e-206 (using 126559/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestCommentCount: p=2.8889823566087328e-70 (using 118986/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator: p=1.1257083511552487e-52 (using 53008/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter: p=4.987380113525745e-11 (using 14035/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueSubmissionCount: p=2.587195754971355e-218 (using 141101/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueCommentCount: p=1.9986965455267647e-192 (using 150656/182997 entries.)\n",
      "(significant) sqrt(1 + ControlPullRequestLifeTimeInMinutes): p=1.7509738397352212e-115 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + ControlPullRequestLifeTimeInMinutes): p=1.9148897076128475e-19 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + ControlPullRequestLifeTimeInMinutes): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) log10(1 + ControlPullRequestLifeTimeInMinutes): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) 1 / (1 + ControlPullRequestLifeTimeInMinutes): p=4.563810648641685e-99 (using 182997/182997 entries.)\n",
      "(significant) ControlPullRequestLifeTimeInMinutes^2: p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ControlPullRequestLifeTimeInMinutes^3: p=1.8428964773703003e-121 (using 182997/182997 entries.)\n",
      "(significant) yj(ControlPullRequestLifeTimeInMinutes): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) sqrt(1 + ControlNumberOfCommitsInPullRequest): p=4.0980984138871424e-53 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + ControlNumberOfCommitsInPullRequest): p=1.1250884593140331e-96 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + ControlNumberOfCommitsInPullRequest): p=5.556971457039637e-196 (using 182677/182997 entries.)\n",
      "(significant) log10(1 + ControlNumberOfCommitsInPullRequest): p=2.589164580801072e-192 (using 182677/182997 entries.)\n",
      "(significant) 1 / (1 + ControlNumberOfCommitsInPullRequest): p=5.580132391310057e-159 (using 182997/182997 entries.)\n",
      "(significant) ControlNumberOfCommitsInPullRequest^2: p=4.638904122634686e-24 (using 182677/182997 entries.)\n",
      "(significant) ControlNumberOfCommitsInPullRequest^3: p=2.4931530860032993e-07 (using 182677/182997 entries.)\n",
      "(significant) yj(ControlNumberOfCommitsInPullRequest): p=1.0256968587395878e-54 (using 182677/182997 entries.)\n",
      "(significant) sqrt(1 + ControlIntraProjectPullRequestExperienceOfIntegrator): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + ControlIntraProjectPullRequestExperienceOfIntegrator): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + ControlIntraProjectPullRequestExperienceOfIntegrator): p=0.0 (using 179287/182997 entries.)\n",
      "(significant) log10(1 + ControlIntraProjectPullRequestExperienceOfIntegrator): p=0.0 (using 179287/182997 entries.)\n",
      "(significant) 1 / (1 + ControlIntraProjectPullRequestExperienceOfIntegrator): p=3.6852510529382143e-121 (using 182997/182997 entries.)\n",
      "(significant) ControlIntraProjectPullRequestExperienceOfIntegrator^2: p=1.148747328145692e-47 (using 179287/182997 entries.)\n",
      "(significant) ControlIntraProjectPullRequestExperienceOfIntegrator^3: p=3.8752601310528752e-31 (using 179287/182997 entries.)\n",
      "(significant) yj(ControlIntraProjectPullRequestExperienceOfIntegrator): p=0.0 (using 179287/182997 entries.)\n",
      "(significant) sqrt(1 + IntraProjectSubmitterPullRequestSubmissionCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + IntraProjectSubmitterPullRequestSubmissionCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + IntraProjectSubmitterPullRequestSubmissionCount): p=8.206997453444943e-119 (using 129195/182997 entries.)\n",
      "(significant) log10(1 + IntraProjectSubmitterPullRequestSubmissionCount): p=1.9164721600603947e-117 (using 129195/182997 entries.)\n",
      "(significant) 1 / (1 + IntraProjectSubmitterPullRequestSubmissionCount): p=3.958607402314325e-179 (using 182997/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSubmissionCount^2: p=9.546413905252472e-46 (using 129195/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSubmissionCount^3: p=2.1903560479148131e-26 (using 129195/182997 entries.)\n",
      "(significant) yj(IntraProjectSubmitterPullRequestSubmissionCount): p=1.0199115868083055e-64 (using 129195/182997 entries.)\n",
      "(significant) sqrt(1 + IntraProjectSubmitterPullRequestSuccessRate): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + IntraProjectSubmitterPullRequestSuccessRate): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + IntraProjectSubmitterPullRequestSuccessRate): p=1.2521927573076653e-05 (using 119303/182997 entries.)\n",
      "(significant) log10(1 + IntraProjectSubmitterPullRequestSuccessRate): p=2.590052513859946e-05 (using 119303/182997 entries.)\n",
      "(significant) 1 / (1 + IntraProjectSubmitterPullRequestSuccessRate): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSuccessRate^2: p=3.8957051390157135e-184 (using 119303/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestSuccessRate^3: p=0.0 (using 119303/182997 entries.)\n",
      "(significant) yj(IntraProjectSubmitterPullRequestSuccessRate): p=6.807911323889666e-78 (using 119303/182997 entries.)\n",
      "(significant) sqrt(1 + IntraProjectSubmitterPullRequestCommentCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + IntraProjectSubmitterPullRequestCommentCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + IntraProjectSubmitterPullRequestCommentCount): p=6.318991967151784e-141 (using 113692/182997 entries.)\n",
      "(significant) log10(1 + IntraProjectSubmitterPullRequestCommentCount): p=1.750869267179031e-143 (using 113692/182997 entries.)\n",
      "(significant) 1 / (1 + IntraProjectSubmitterPullRequestCommentCount): p=1.2871024152850867e-44 (using 182997/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestCommentCount^2: p=0.00602349549055509 (using 113692/182997 entries.)\n",
      "(significant) IntraProjectSubmitterPullRequestCommentCount^3: p=0.04716516194980503 (using 113692/182997 entries.)\n",
      "(significant) yj(IntraProjectSubmitterPullRequestCommentCount): p=2.5093091718607952e-58 (using 113692/182997 entries.)\n",
      "(significant) sqrt(1 + EcosystemExperienceSubmitterPullRequestSuccessRate): p=1.633852737926027e-102 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + EcosystemExperienceSubmitterPullRequestSuccessRate): p=4.66004455801199e-114 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + EcosystemExperienceSubmitterPullRequestSuccessRate): p=0.013926206697219822 (using 117490/182997 entries.)\n",
      "(significant) log10(1 + EcosystemExperienceSubmitterPullRequestSuccessRate): p=0.008515599991137678 (using 117490/182997 entries.)\n",
      "(significant) 1 / (1 + EcosystemExperienceSubmitterPullRequestSuccessRate): p=3.749508918086047e-218 (using 182997/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSuccessRate^2: p=2.3472307985258566e-104 (using 117490/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSuccessRate^3: p=2.7950015132453177e-219 (using 117490/182997 entries.)\n",
      "(significant) yj(EcosystemExperienceSubmitterPullRequestSuccessRate): p=1.488520063528953e-18 (using 117490/182997 entries.)\n",
      "(significant) sqrt(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount): p=2.314227665366738e-179 (using 182997/182997 entries.)\n",
      "(insignificant) ln(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount): p=0.11138731600372132 (using 126559/182997 entries.)\n",
      "(insignificant) log10(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount): p=0.11189573291406733 (using 126559/182997 entries.)\n",
      "(significant) 1 / (1 + EcosystemExperienceSubmitterPullRequestSubmissionCount): p=6.700417395477105e-126 (using 182997/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSubmissionCount^2: p=3.0749380061820724e-60 (using 126559/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestSubmissionCount^3: p=4.349528292021303e-14 (using 126559/182997 entries.)\n",
      "(significant) yj(EcosystemExperienceSubmitterPullRequestSubmissionCount): p=4.923446510582871e-09 (using 126559/182997 entries.)\n",
      "(significant) sqrt(1 + EcosystemExperienceSubmitterPullRequestCommentCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + EcosystemExperienceSubmitterPullRequestCommentCount): p=1.3892146883868885e-283 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + EcosystemExperienceSubmitterPullRequestCommentCount): p=8.060998418852018e-17 (using 118986/182997 entries.)\n",
      "(significant) log10(1 + EcosystemExperienceSubmitterPullRequestCommentCount): p=2.9124117750984075e-17 (using 118986/182997 entries.)\n",
      "(significant) 1 / (1 + EcosystemExperienceSubmitterPullRequestCommentCount): p=2.0012838976463843e-62 (using 182997/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterPullRequestCommentCount^2: p=3.912493626565009e-06 (using 118986/182997 entries.)\n",
      "(insignificant) EcosystemExperienceSubmitterPullRequestCommentCount^3: p=0.17209887282904246 (using 118986/182997 entries.)\n",
      "(insignificant) yj(EcosystemExperienceSubmitterPullRequestCommentCount): p=0.44740253720024237 (using 118986/182997 entries.)\n",
      "(significant) sqrt(1 + SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=2.8015852706927512e-101 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=9.390426769319883e-49 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=8.92813768113618e-08 (using 53008/182997 entries.)\n",
      "(significant) log10(1 + SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=1.5981121479757642e-07 (using 53008/182997 entries.)\n",
      "(significant) 1 / (1 + SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=2.841257984125848e-79 (using 182997/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator^2: p=3.262167292267527e-28 (using 53008/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator^3: p=7.914550106013105e-16 (using 53008/182997 entries.)\n",
      "(significant) yj(SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator): p=5.2781926038172724e-17 (using 53008/182997 entries.)\n",
      "(significant) sqrt(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=8.775306926438205e-160 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=9.555601405995476e-122 (using 182997/182997 entries.)\n",
      "(insignificant) ln(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=0.7072858636669521 (using 14035/182997 entries.)\n",
      "(insignificant) log10(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=0.6972347977482825 (using 14035/182997 entries.)\n",
      "(significant) 1 / (1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=0.017637710824406416 (using 182997/182997 entries.)\n",
      "(significant) SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter^2: p=0.0007378278745837143 (using 14035/182997 entries.)\n",
      "(insignificant) SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter^3: p=0.31418443063768087 (using 14035/182997 entries.)\n",
      "(significant) yj(SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter): p=0.002012139137791584 (using 14035/182997 entries.)\n",
      "(significant) sqrt(1 + EcosystemExperienceSubmitterIssueSubmissionCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + EcosystemExperienceSubmitterIssueSubmissionCount): p=4.540848985994452e-191 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + EcosystemExperienceSubmitterIssueSubmissionCount): p=4.2209413066423303e-16 (using 141101/182997 entries.)\n",
      "(significant) log10(1 + EcosystemExperienceSubmitterIssueSubmissionCount): p=9.34541358283979e-17 (using 141101/182997 entries.)\n",
      "(significant) 1 / (1 + EcosystemExperienceSubmitterIssueSubmissionCount): p=1.3607047246928367e-199 (using 182997/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueSubmissionCount^2: p=1.2141362891757969e-64 (using 141101/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueSubmissionCount^3: p=2.8392954111243964e-17 (using 141101/182997 entries.)\n",
      "(significant) yj(EcosystemExperienceSubmitterIssueSubmissionCount): p=0.011815727837878933 (using 141101/182997 entries.)\n",
      "(significant) sqrt(1 + EcosystemExperienceSubmitterIssueCommentCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) cbrt(1 + EcosystemExperienceSubmitterIssueCommentCount): p=0.0 (using 182997/182997 entries.)\n",
      "(significant) ln(1 + EcosystemExperienceSubmitterIssueCommentCount): p=2.235379730651808e-52 (using 150656/182997 entries.)\n",
      "(significant) log10(1 + EcosystemExperienceSubmitterIssueCommentCount): p=4.699495275063511e-55 (using 150656/182997 entries.)\n",
      "(significant) 1 / (1 + EcosystemExperienceSubmitterIssueCommentCount): p=2.170218803708333e-242 (using 182997/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueCommentCount^2: p=7.162325219162923e-29 (using 150656/182997 entries.)\n",
      "(significant) EcosystemExperienceSubmitterIssueCommentCount^3: p=1.145445846058471e-07 (using 150656/182997 entries.)\n",
      "(significant) yj(EcosystemExperienceSubmitterIssueCommentCount): p=6.530233825712715e-28 (using 150656/182997 entries.)\n",
      "[\n",
      "    \"ln(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount)\",\n",
      "    \"log10(1 + EcosystemExperienceSubmitterPullRequestSubmissionCount)\",\n",
      "    \"EcosystemExperienceSubmitterPullRequestCommentCount^3\",\n",
      "    \"yj(EcosystemExperienceSubmitterPullRequestCommentCount)\",\n",
      "    \"ln(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter)\",\n",
      "    \"log10(1 + SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter)\",\n",
      "    \"SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter^3\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "continuous_vars = independent.select_dtypes(include='number').columns\n",
    "\n",
    "tr_independent = independent.copy()\n",
    "\n",
    "for field in continuous_vars:\n",
    "    tr_independent[f'sqrt(1 + {field})'] =  independent[field].apply(lambda x: math.sqrt(1 + x))\n",
    "    tr_independent[f'cbrt(1 + {field})'] =  independent[field].apply(lambda x: math.cbrt(1 + x))\n",
    "    tr_independent[f'ln(1 + {field})'] =  independent[field].apply(lambda x: math.log(1 + x))\n",
    "    tr_independent[f'log10(1 + {field})'] =  independent[field].apply(lambda x: math.log10(1 + x))\n",
    "    tr_independent[f'1 / (1 + {field})'] =  independent[field].apply(lambda x: 1 / (1 + x))\n",
    "    tr_independent[f'{field}^2'] =  independent[field].apply(lambda x: x ** 2)\n",
    "    tr_independent[f'{field}^3'] =  independent[field].apply(lambda x: x ** 3)\n",
    "    tr_independent[f'yj({field})'], _lambda = yeojohnson(independent[field])\n",
    "\n",
    "\n",
    "test_log_odds_independence(tr_independent)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NOTE: Some (3) of the variables pass after this transformation.\n",
    "# - EcosystemExperienceSubmitterPullRequestSubmissionCount\n",
    "# - EcosystemExperienceSubmitterPullRequestCommentCount\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(\n",
    "#         lambda x: math.sqrt(1 + x))\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# # NOTE: one of the variables pass after this transformation:\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(\n",
    "#         lambda x: math.log(1 + x))\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: this works for one\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(\n",
    "#         lambda x: math.log10(1 + x))\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: this works for three:\n",
    "# - EcosystemExperienceSubmitterPullRequestCommentCount\n",
    "# - SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: 1/(x+1))\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: This works for three.\n",
    "# - IntraProjectSubmitterPullRequestSubmissionCount\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# - EcosystemExperienceSubmitterIssueCommentCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: x**2)\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: This works for two:\n",
    "# - SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter   _lambda=-5.845365889174542 (reciprocal with sign preservation)\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount                         _lambda=-0.12955260658759882 (power transform with sign preservation)\n",
    "# for field in continuous_vars:\n",
    "#     transformed, _lambda = yeojohnson(independent[field])\n",
    "#     print(f'{field=}, {_lambda=}')\n",
    "#     tr_independent[field] = transformed\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: This does nothing.\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[f'squared_{field}'] = independent[field].apply(lambda x: x**2)\n",
    "#     tr_independent[f'cubed_{field}'] = independent[field].apply(lambda x: x**3)\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: cubic root. Works for\n",
    "# - EcosystemExperienceSubmitterPullRequestSubmissionCount\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# - IntraProjectSubmitterPullRequestCommentCount\n",
    "# for field in continuous_vars:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: np.cbrt(x + 1))\n",
    "# test_log_odds_independence(tr_independent)\n",
    "\n",
    "# NOTE: works for six:\n",
    "# - EcosystemExperienceSubmitterPullRequestSubmissionCount\n",
    "# - EcosystemExperienceSubmitterPullRequestCommentCount\n",
    "# - SharedExperiencePullRequestSubmittedBySubmitterIntegratedByIntegrator\n",
    "# - SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter\n",
    "# - EcosystemExperienceSubmitterIssueSubmissionCount\n",
    "# - EcosystemExperienceSubmitterIssueCommentCount\n",
    "# sqrt_transform = [\"EcosystemExperienceSubmitterPullRequestSubmissionCount\",\n",
    "#                   \"EcosystemExperienceSubmitterPullRequestCommentCount\", \"EcosystemExperienceSubmitterIssueSubmissionCount\"]\n",
    "# for field in sqrt_transform:\n",
    "#     tr_independent[field] = independent[field].apply(\n",
    "#         lambda x: math.sqrt(1 + x))\n",
    "# log_transform = []\n",
    "# for field in log_transform:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: math.log(1 + x))\n",
    "# power_transform = []\n",
    "# for field in power_transform:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: x ** 2)\n",
    "# recip_transform = [\n",
    "#     \"SharedExperiencePullRequestSubmittedByIntegratorIntegratedBySubmitter\"]\n",
    "# for field in recip_transform:\n",
    "#     tr_independent[field] = independent[field].apply(lambda x: 1 / (1+x))\n",
    "# test_log_odds_independence(tr_independent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
